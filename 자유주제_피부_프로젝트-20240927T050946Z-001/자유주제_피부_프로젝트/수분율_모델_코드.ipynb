{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8MV4z5-jKU-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from collections import Counter\n",
        "\n",
        "# Custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = os.listdir(root_dir)\n",
        "        self.data = []\n",
        "\n",
        "        for label in range(len(self.classes)):\n",
        "            class_folder = os.path.join(root_dir, self.classes[label])\n",
        "            for filename in os.listdir(class_folder):\n",
        "                img_path = os.path.join(class_folder, filename)\n",
        "                self.data.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx]\n",
        "        image = Image.open(img_path).convert('RGB')  # 이미지 RGB로 변환\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# 경로 및 배치 크기 설정\n",
        "base_dir = './uploadfolder'  # 베이스 경로 (압축을 푼 폴더 경로)\n",
        "batch_size = 16\n",
        "\n",
        "# 통합된 train 및 valid 폴더 경로 설정\n",
        "train_dir = os.path.join(base_dir, '찐막', 'train')\n",
        "valid_dir = os.path.join(base_dir, '찐막', 'valid')\n",
        "\n",
        "# 데이터 증강 포함한 이미지 전처리\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomRotation(15),  # 더 큰 회전 각도\n",
        "    T.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 이미지 이동\n",
        "    T.GaussianBlur(kernel_size=3),  # Gaussian Blur 추가\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 학습 및 검증 데이터셋 생성\n",
        "train_dataset = CustomDataset(train_dir, transform=transform)\n",
        "valid_dataset = CustomDataset(valid_dir, transform=transform)\n",
        "\n",
        "# train 데이터셋이 비어있는지 확인\n",
        "if len(train_dataset) == 0:\n",
        "    raise ValueError(\"Train dataset is empty. Check if the images are correctly loaded.\")\n",
        "\n",
        "# 각 클래스의 데이터 개수 계산 (Counter 사용)\n",
        "class_counts = Counter([label for _, label in train_dataset])\n",
        "\n",
        "# 클래스별로 가중치를 부여 (데이터 개수의 역수 사용)\n",
        "class_weights = {cls: 1.0 / count for cls, count in class_counts.items()}\n",
        "\n",
        "# 각 샘플의 가중치를 리스트로 변환\n",
        "sample_weights = [class_weights[label] for _, label in train_dataset]\n",
        "\n",
        "# 샘플 가중치가 비어있는지 확인\n",
        "if len(sample_weights) == 0:\n",
        "    raise ValueError(\"Sample weights are empty. Check the dataset loading process.\")\n",
        "\n",
        "# WeightedRandomSampler 생성\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# WeightedRandomSampler를 적용한 DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 사전 학습된 resnext50_32x4d 모델 사용\n",
        "from torchvision.models import ResNeXt50_32X4D_Weights\n",
        "\n",
        "weights = ResNeXt50_32X4D_Weights.DEFAULT\n",
        "model = models.resnext50_32x4d(weights=weights)\n",
        "\n",
        "# 모든 레이어 학습 가능하도록 설정 (전이 학습 제외)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 출력 레이어를 분류하려는 클래스 수에 맞게 수정 (드롭아웃 비율 0.3으로 설정)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.3),  # Dropout 비율을 0.3으로 조정\n",
        "    nn.Linear(model.fc.in_features, len(train_dataset.classes))\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Early Stopping 설정\n",
        "best_accuracy = 0\n",
        "patience = 5  # 개선되지 않는 에포크를 허용하는 최대 수\n",
        "counter = 0\n",
        "\n",
        "# 손실 함수 및 AdamW 옵티마이저 설정 (학습률 0.0001로 감소)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 학습률 스케줄러 추가 (학습률 점진적 감소, gamma=0.5, step_size=10)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "# 학습 과정 (TQDM으로 진행 상황 시각화, 에포크 30)\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    # TQDM으로 학습 진행 표시\n",
        "    train_loader_iter = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    for images, labels in train_loader_iter:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loader_iter.set_postfix(loss=running_loss / len(train_loader))\n",
        "\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Train Accuracy: {train_accuracy}%\")\n",
        "\n",
        "    # 학습률 스케줄러 업데이트\n",
        "    scheduler.step()\n",
        "\n",
        "    # 검증 평가\n",
        "    model.eval()\n",
        "    correct_valid = 0\n",
        "    total_valid = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_valid += labels.size(0)\n",
        "            correct_valid += (predicted == labels).sum().item()\n",
        "\n",
        "    valid_accuracy = 100 * correct_valid / total_valid\n",
        "    print(f'Validation Accuracy: {valid_accuracy}%')\n",
        "\n",
        "    # Early Stopping 기준\n",
        "    if valid_accuracy > best_accuracy:\n",
        "        best_accuracy = valid_accuracy\n",
        "        counter = 0  # 성능 개선 시 카운터 초기화\n",
        "        torch.save(model.state_dict(), 'best_model.pth')  # 최적의 모델 저장\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping 적용\")\n",
        "            break\n"
      ]
    }
  ]
}